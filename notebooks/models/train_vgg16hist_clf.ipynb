{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["U ovoj bilježnici isprobavamo vgg16 model uz metodu izjednačavanja histograma provedeno na slikama."],"metadata":{"id":"VR0K4e6kROVM"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFs3MGR7eYDW","executionInfo":{"status":"ok","timestamp":1672336851028,"user_tz":-60,"elapsed":15976,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"16be8d07-3a83-488f-fc47-29656a67b477"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import cv2 as cv\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from sklearn import metrics"],"metadata":{"id":"1pNDXgXifSjX","executionInfo":{"status":"ok","timestamp":1672336879602,"user_tz":-60,"elapsed":3872,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/gdrive/MyDrive/asub_dataset/preprocessed_newest/train.csv')\n","valid_df = pd.read_csv('/content/gdrive/MyDrive/asub_dataset/preprocessed_newest/validation.csv')\n","test_df = pd.read_csv('/content/gdrive/MyDrive/asub_dataset/preprocessed_newest/test.csv')\n","\n","train_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Y-1aGO2bgRr5","executionInfo":{"status":"ok","timestamp":1672336881729,"user_tz":-60,"elapsed":799,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"4781f976-19d1-4bec-fc03-4da422d015cf"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      label                                               path\n","0         1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","1         0  /content/gdrive/MyDrive/asub_dataset/preproces...\n","2         1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","3         0  /content/gdrive/MyDrive/asub_dataset/preproces...\n","4         0  /content/gdrive/MyDrive/asub_dataset/preproces...\n","...     ...                                                ...\n","1915      1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","1916      1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","1917      1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","1918      1  /content/gdrive/MyDrive/asub_dataset/preproces...\n","1919      0  /content/gdrive/MyDrive/asub_dataset/preproces...\n","\n","[1920 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-5fd24a0e-898c-4270-91e5-8261e0815110\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1915</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>1916</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>1917</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>1918</th>\n","      <td>1</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","    <tr>\n","      <th>1919</th>\n","      <td>0</td>\n","      <td>/content/gdrive/MyDrive/asub_dataset/preproces...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1920 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fd24a0e-898c-4270-91e5-8261e0815110')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5fd24a0e-898c-4270-91e5-8261e0815110 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5fd24a0e-898c-4270-91e5-8261e0815110');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# ucitavanje skupa podataka\n","X_train = []\n","y_train = []\n","for i in range(len(train_df)):\n","    img = cv.imread(train_df['path'][i])\n","    img_grayScaled = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","    img_equ = cv.equalizeHist(img_grayScaled)\n","\n","    img_final = cv.cvtColor(img_equ, cv.COLOR_GRAY2BGR)\n","\n","    X_train.append(np.array(img_final))\n","    y_train.append(train_df['label'][i])\n"],"metadata":{"id":"zXM1GuqMjWXC","executionInfo":{"status":"ok","timestamp":1672337175517,"user_tz":-60,"elapsed":291174,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ucitavanje skupa podataka\n","X_validation = []\n","y_validation = []\n","for i in range(len(valid_df)):\n","    img = cv.imread(valid_df['path'][i])\n","    img_grayScaled = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","    img_equ = cv.equalizeHist(img_grayScaled)\n","    img_final = cv.cvtColor(img_equ, cv.COLOR_GRAY2BGR)\n","\n","    X_validation.append(np.array(img_final))\n","    y_validation.append(valid_df['label'][i])\n","    "],"metadata":{"id":"t5fctkYQl9TC","executionInfo":{"status":"ok","timestamp":1672337301846,"user_tz":-60,"elapsed":70521,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# ucitavanje skupa podataka\n","X_test = []\n","y_test = []\n","for i in range(len(test_df)):\n","    img = cv.imread(test_df['path'][i])\n","    img_grayScaled = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","    img_equ = cv.equalizeHist(img_grayScaled)\n","    img_final = cv.cvtColor(img_equ, cv.COLOR_GRAY2BGR)\n","\n","    X_test.append(np.array(img_final))\n","    y_test.append(test_df['label'][i])\n","    "],"metadata":{"id":"hobdEybymwI2","executionInfo":{"status":"ok","timestamp":1672337407599,"user_tz":-60,"elapsed":87192,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# pretvorba u numpy array\n","X_train = np.array(X_train)\n","X_validation = np.array(X_validation)\n","X_test = np.array(X_test)\n","\n","y_train = np.array(y_train)\n","y_validation = np.array(y_validation)\n","y_test = np.array(y_test)"],"metadata":{"id":"iuu8FFJtoFP3","executionInfo":{"status":"ok","timestamp":1672337415161,"user_tz":-60,"elapsed":388,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#provjera dimenzija\n","\n","print(\"Shape X_train: {0}\".format(X_train.shape))\n","print(\"Shape X_validation: {0}\".format(X_validation.shape))\n","print(\"Shape X_test: {0}\".format(X_test.shape))\n","print(\"Shape y_train: {0}\".format(y_train.shape))\n","print(\"Shape y_validation: {0}\".format(y_validation.shape))\n","print(\"Shape y_test: {0}\".format(y_test.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SryLaZCKn6M-","executionInfo":{"status":"ok","timestamp":1672337422779,"user_tz":-60,"elapsed":238,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"6ea085db-0309-4ea5-c21b-de7b8a57b5cb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape X_train: (1920, 200, 200, 3)\n","Shape X_validation: (480, 200, 200, 3)\n","Shape X_test: (600, 200, 200, 3)\n","Shape y_train: (1920,)\n","Shape y_validation: (480,)\n","Shape y_test: (600,)\n"]}]},{"cell_type":"code","source":["#train_datagen = ImageDataGenerator(rescale=1./255., rotation_range=40, width_shift_range=.2, height_shift_range=.2, shear_range=.2, zoom_range=.2, horizontal_flip=True)\n","#validation_datagen = ImageDataGenerator(rescale=1./255.)\n","#test_datagen = ImageDataGenerator(rescale=1./255.)"],"metadata":{"id":"PksC0C5SoTLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalizacija\n","train_x = tf.keras.utils.normalize(X_train, axis=1)\n","test_x = tf.keras.utils.normalize(X_test, axis=1)\n","validation_x = tf.keras.utils.normalize(X_validation, axis=1)"],"metadata":{"id":"9vwya-6Uq2tV","executionInfo":{"status":"ok","timestamp":1672337427698,"user_tz":-60,"elapsed":2699,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# definiramo callback funkcije koje pomazu kod procesa ucenja\n","# ReduceLROnPlateau cemo koristiti umjesto da optimiramo hiperparametar stope ucenja\n","# ako u 2 epohe nismo dobili bolji validation loss, smanjujemo za lr za definirani faktor\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=2,\n","    min_lr=1e-9,\n","    verbose=1\n",")\n","\n","# ovo je callback koji omogućuje spremanje modela ovisno o accuracyu na validation setu\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal',\n","    monitor='val_acc',\n","    save_best_only=True,\n","    verbose=1\n",")"],"metadata":{"id":"vaGfJhYgzuau","executionInfo":{"status":"ok","timestamp":1672337430481,"user_tz":-60,"elapsed":249,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["## radi se grid search na veličinu batcha\n","for bs in [16, 32, 64]:\n","  print('Batch size: {0}\\n'.format(bs))\n","\n","  \"\"\"\n","  train_generator = train_datagen.flow(\n","      X_train, y_train,\n","      batch_size=batch_size\n","  )\n","\n","  validation_generator = validation_datagen.flow(\n","      X_validation, y_validation,\n","      batch_size=batch_size\n","  )\n","  \"\"\"\n","\n","  model_vgg16 = VGG16(\n","  input_shape=(200, 200, 3),\n","  include_top=False,\n","  weights='imagenet'\n","  )\n","\n","  for layer in model_vgg16.layers:\n","      layer.trainable = False\n","\n","  x = layers.Flatten()(model_vgg16.output)\n","  x = layers.Dropout(0.25)(x)\n","\n","  x = layers.Dense(units=256, activation=\"relu\")(x)\n","  x = layers.Dense(units=1, activation=\"sigmoid\")(x)\n","  model = tf.keras.Model(model_vgg16.input, x)\n","\n","  model.compile(\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n","      loss=tf.keras.losses.BinaryCrossentropy(),\n","      metrics = ['acc']\n","  )\n","\n","  ## na kraju treniramo model\n","  vgg = model.fit(x=train_x, y=y_train, \n","                  validation_data=(validation_x, y_validation),\n","                  batch_size=bs,\n","                  epochs=40, \n","                  verbose=1, \n","                  callbacks=[reduce_lr, checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crp4VYZLD5y1","outputId":"78e2d8c6-57cc-40ef-8cc5-805e34b8d202","executionInfo":{"status":"ok","timestamp":1672338835356,"user_tz":-60,"elapsed":1397507,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch size: 16\n","\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 1s 0us/step\n","Epoch 1/40\n","120/120 [==============================] - ETA: 0s - loss: 0.6322 - acc: 0.7255\n","Epoch 1: val_acc improved from -inf to 0.81042, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 23s 121ms/step - loss: 0.6322 - acc: 0.7255 - val_loss: 0.3818 - val_acc: 0.8104 - lr: 0.0010\n","Epoch 2/40\n","120/120 [==============================] - ETA: 0s - loss: 0.3392 - acc: 0.8464\n","Epoch 2: val_acc improved from 0.81042 to 0.89375, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 13s 110ms/step - loss: 0.3392 - acc: 0.8464 - val_loss: 0.2636 - val_acc: 0.8938 - lr: 0.0010\n","Epoch 3/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2717 - acc: 0.8917\n","Epoch 3: val_acc did not improve from 0.89375\n","120/120 [==============================] - 10s 84ms/step - loss: 0.2717 - acc: 0.8917 - val_loss: 0.3115 - val_acc: 0.8625 - lr: 0.0010\n","Epoch 4/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2241 - acc: 0.9135\n","Epoch 4: val_acc did not improve from 0.89375\n","120/120 [==============================] - 10s 84ms/step - loss: 0.2241 - acc: 0.9135 - val_loss: 0.2582 - val_acc: 0.8854 - lr: 0.0010\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2064 - acc: 0.9198\n","Epoch 5: val_acc improved from 0.89375 to 0.93125, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 13s 107ms/step - loss: 0.2064 - acc: 0.9198 - val_loss: 0.1809 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 6/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1716 - acc: 0.9292\n","Epoch 6: val_acc improved from 0.93125 to 0.95000, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 13s 110ms/step - loss: 0.1716 - acc: 0.9292 - val_loss: 0.1732 - val_acc: 0.9500 - lr: 0.0010\n","Epoch 7/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1317 - acc: 0.9573\n","Epoch 7: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 90ms/step - loss: 0.1317 - acc: 0.9573 - val_loss: 0.1851 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 8/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1246 - acc: 0.9495\n","Epoch 8: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 91ms/step - loss: 0.1246 - acc: 0.9495 - val_loss: 0.1678 - val_acc: 0.9396 - lr: 0.0010\n","Epoch 9/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0945 - acc: 0.9635\n","Epoch 9: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 91ms/step - loss: 0.0945 - acc: 0.9635 - val_loss: 0.1625 - val_acc: 0.9375 - lr: 0.0010\n","Epoch 10/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1277 - acc: 0.9479\n","Epoch 10: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 93ms/step - loss: 0.1277 - acc: 0.9479 - val_loss: 0.2006 - val_acc: 0.9292 - lr: 0.0010\n","Epoch 11/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9516\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 11: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.1303 - acc: 0.9516 - val_loss: 0.5955 - val_acc: 0.7979 - lr: 0.0010\n","Epoch 12/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0988 - acc: 0.9620\n","Epoch 12: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0988 - acc: 0.9620 - val_loss: 0.1425 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 13/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0685 - acc: 0.9760\n","Epoch 13: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0685 - acc: 0.9760 - val_loss: 0.1448 - val_acc: 0.9500 - lr: 2.0000e-04\n","Epoch 14/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0619 - acc: 0.9818\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 14: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0619 - acc: 0.9818 - val_loss: 0.1628 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 15/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.9849\n","Epoch 15: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0560 - acc: 0.9849 - val_loss: 0.1465 - val_acc: 0.9438 - lr: 4.0000e-05\n","Epoch 16/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0540 - acc: 0.9896\n","Epoch 16: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 91ms/step - loss: 0.0540 - acc: 0.9896 - val_loss: 0.1422 - val_acc: 0.9500 - lr: 4.0000e-05\n","Epoch 17/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0511 - acc: 0.9849\n","Epoch 17: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0511 - acc: 0.9849 - val_loss: 0.1454 - val_acc: 0.9438 - lr: 4.0000e-05\n","Epoch 18/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9839\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 18: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0500 - acc: 0.9839 - val_loss: 0.1440 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 19/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9859\n","Epoch 19: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0531 - acc: 0.9859 - val_loss: 0.1482 - val_acc: 0.9417 - lr: 8.0000e-06\n","Epoch 20/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0481 - acc: 0.9885\n","Epoch 20: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0481 - acc: 0.9885 - val_loss: 0.1409 - val_acc: 0.9500 - lr: 8.0000e-06\n","Epoch 21/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.9854\n","Epoch 21: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0556 - acc: 0.9854 - val_loss: 0.1418 - val_acc: 0.9500 - lr: 8.0000e-06\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9854\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 22: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0532 - acc: 0.9854 - val_loss: 0.1451 - val_acc: 0.9438 - lr: 8.0000e-06\n","Epoch 23/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.9875\n","Epoch 23: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0483 - acc: 0.9875 - val_loss: 0.1436 - val_acc: 0.9458 - lr: 1.6000e-06\n","Epoch 24/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.9812\n","Epoch 24: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 24: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0553 - acc: 0.9812 - val_loss: 0.1424 - val_acc: 0.9458 - lr: 1.6000e-06\n","Epoch 25/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0503 - acc: 0.9875\n","Epoch 25: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0503 - acc: 0.9875 - val_loss: 0.1427 - val_acc: 0.9458 - lr: 3.2000e-07\n","Epoch 26/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.9880\n","Epoch 26: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n","\n","Epoch 26: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0463 - acc: 0.9880 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 3.2000e-07\n","Epoch 27/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9865\n","Epoch 27: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0484 - acc: 0.9865 - val_loss: 0.1428 - val_acc: 0.9458 - lr: 6.4000e-08\n","Epoch 28/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9865\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n","\n","Epoch 28: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0470 - acc: 0.9865 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 6.4000e-08\n","Epoch 29/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0516 - acc: 0.9880\n","Epoch 29: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0516 - acc: 0.9880 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.2800e-08\n","Epoch 30/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9885\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n","\n","Epoch 30: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0500 - acc: 0.9885 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.2800e-08\n","Epoch 31/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0517 - acc: 0.9828\n","Epoch 31: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0517 - acc: 0.9828 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 2.5600e-09\n","Epoch 32/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.9885\n","Epoch 32: ReduceLROnPlateau reducing learning rate to 1e-09.\n","\n","Epoch 32: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0514 - acc: 0.9885 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 2.5600e-09\n","Epoch 33/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9859\n","Epoch 33: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 93ms/step - loss: 0.0471 - acc: 0.9859 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 34/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0535 - acc: 0.9870\n","Epoch 34: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0535 - acc: 0.9870 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 35/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0547 - acc: 0.9865\n","Epoch 35: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0547 - acc: 0.9865 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 36/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9870\n","Epoch 36: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0491 - acc: 0.9870 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 37/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9891\n","Epoch 37: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0470 - acc: 0.9891 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 38/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0497 - acc: 0.9839\n","Epoch 38: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0497 - acc: 0.9839 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 39/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0537 - acc: 0.9875\n","Epoch 39: val_acc did not improve from 0.95000\n","120/120 [==============================] - 10s 87ms/step - loss: 0.0537 - acc: 0.9875 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Epoch 40/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0536 - acc: 0.9849\n","Epoch 40: val_acc did not improve from 0.95000\n","120/120 [==============================] - 11s 92ms/step - loss: 0.0536 - acc: 0.9849 - val_loss: 0.1429 - val_acc: 0.9458 - lr: 1.0000e-09\n","Batch size: 32\n","\n","Epoch 1/40\n","60/60 [==============================] - ETA: 0s - loss: 1.1430 - acc: 0.5734\n","Epoch 1: val_acc did not improve from 0.95000\n","60/60 [==============================] - 13s 173ms/step - loss: 1.1430 - acc: 0.5734 - val_loss: 0.5608 - val_acc: 0.7188 - lr: 0.0010\n","Epoch 2/40\n","60/60 [==============================] - ETA: 0s - loss: 0.4949 - acc: 0.7828\n","Epoch 2: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 178ms/step - loss: 0.4949 - acc: 0.7828 - val_loss: 0.4602 - val_acc: 0.8062 - lr: 0.0010\n","Epoch 3/40\n","60/60 [==============================] - ETA: 0s - loss: 0.3931 - acc: 0.8495\n","Epoch 3: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 180ms/step - loss: 0.3931 - acc: 0.8495 - val_loss: 0.3554 - val_acc: 0.8854 - lr: 0.0010\n","Epoch 4/40\n","60/60 [==============================] - ETA: 0s - loss: 0.3333 - acc: 0.8755\n","Epoch 4: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 170ms/step - loss: 0.3333 - acc: 0.8755 - val_loss: 0.3051 - val_acc: 0.8958 - lr: 0.0010\n","Epoch 5/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2723 - acc: 0.9000\n","Epoch 5: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 178ms/step - loss: 0.2723 - acc: 0.9000 - val_loss: 0.2933 - val_acc: 0.8833 - lr: 0.0010\n","Epoch 6/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2441 - acc: 0.9057\n","Epoch 6: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 167ms/step - loss: 0.2441 - acc: 0.9057 - val_loss: 0.3555 - val_acc: 0.8271 - lr: 0.0010\n","Epoch 7/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.9354\n","Epoch 7: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 177ms/step - loss: 0.2022 - acc: 0.9354 - val_loss: 0.2391 - val_acc: 0.9104 - lr: 0.0010\n","Epoch 8/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1880 - acc: 0.9328\n","Epoch 8: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 166ms/step - loss: 0.1880 - acc: 0.9328 - val_loss: 0.2026 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 9/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1854 - acc: 0.9302\n","Epoch 9: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 166ms/step - loss: 0.1854 - acc: 0.9302 - val_loss: 0.2672 - val_acc: 0.8875 - lr: 0.0010\n","Epoch 10/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1924 - acc: 0.9198\n","Epoch 10: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 167ms/step - loss: 0.1924 - acc: 0.9198 - val_loss: 0.1774 - val_acc: 0.9333 - lr: 0.0010\n","Epoch 11/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1341 - acc: 0.9536\n","Epoch 11: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 181ms/step - loss: 0.1341 - acc: 0.9536 - val_loss: 0.2067 - val_acc: 0.9083 - lr: 0.0010\n","Epoch 12/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1319 - acc: 0.9531\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 12: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 168ms/step - loss: 0.1319 - acc: 0.9531 - val_loss: 0.1787 - val_acc: 0.9250 - lr: 0.0010\n","Epoch 13/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1073 - acc: 0.9667\n","Epoch 13: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 178ms/step - loss: 0.1073 - acc: 0.9667 - val_loss: 0.1690 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 14/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1072 - acc: 0.9708\n","Epoch 14: val_acc did not improve from 0.95000\n","60/60 [==============================] - 11s 178ms/step - loss: 0.1072 - acc: 0.9708 - val_loss: 0.1618 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 15/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0997 - acc: 0.9703\n","Epoch 15: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0997 - acc: 0.9703 - val_loss: 0.1634 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 16/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0935 - acc: 0.9734\n","Epoch 16: val_acc did not improve from 0.95000\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0935 - acc: 0.9734 - val_loss: 0.1596 - val_acc: 0.9500 - lr: 2.0000e-04\n","Epoch 17/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1038 - acc: 0.9656\n","Epoch 17: val_acc improved from 0.95000 to 0.95208, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 12s 202ms/step - loss: 0.1038 - acc: 0.9656 - val_loss: 0.1634 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 18/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0958 - acc: 0.9750\n","Epoch 18: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 176ms/step - loss: 0.0958 - acc: 0.9750 - val_loss: 0.1579 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 19/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0912 - acc: 0.9734\n","Epoch 19: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0912 - acc: 0.9734 - val_loss: 0.1783 - val_acc: 0.9375 - lr: 2.0000e-04\n","Epoch 20/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0898 - acc: 0.9755\n","Epoch 20: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0898 - acc: 0.9755 - val_loss: 0.1571 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 21/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0914 - acc: 0.9750\n","Epoch 21: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0914 - acc: 0.9750 - val_loss: 0.1618 - val_acc: 0.9354 - lr: 2.0000e-04\n","Epoch 22/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.9766\n","Epoch 22: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0858 - acc: 0.9766 - val_loss: 0.1559 - val_acc: 0.9396 - lr: 2.0000e-04\n","Epoch 23/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0850 - acc: 0.9776\n","Epoch 23: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0850 - acc: 0.9776 - val_loss: 0.1541 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 24/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0846 - acc: 0.9786\n","Epoch 24: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0846 - acc: 0.9786 - val_loss: 0.1545 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 25/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0778 - acc: 0.9812\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 25: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0778 - acc: 0.9812 - val_loss: 0.1568 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 26/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0742 - acc: 0.9818\n","Epoch 26: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0742 - acc: 0.9818 - val_loss: 0.1532 - val_acc: 0.9479 - lr: 4.0000e-05\n","Epoch 27/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0736 - acc: 0.9771\n","Epoch 27: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0736 - acc: 0.9771 - val_loss: 0.1543 - val_acc: 0.9479 - lr: 4.0000e-05\n","Epoch 28/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0740 - acc: 0.9797\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 28: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0740 - acc: 0.9797 - val_loss: 0.1579 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 29/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0660 - acc: 0.9885\n","Epoch 29: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 168ms/step - loss: 0.0660 - acc: 0.9885 - val_loss: 0.1538 - val_acc: 0.9479 - lr: 8.0000e-06\n","Epoch 30/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0724 - acc: 0.9823\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 30: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0724 - acc: 0.9823 - val_loss: 0.1543 - val_acc: 0.9479 - lr: 8.0000e-06\n","Epoch 31/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.9807\n","Epoch 31: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 168ms/step - loss: 0.0770 - acc: 0.9807 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 1.6000e-06\n","Epoch 32/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0732 - acc: 0.9818\n","Epoch 32: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 32: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0732 - acc: 0.9818 - val_loss: 0.1541 - val_acc: 0.9479 - lr: 1.6000e-06\n","Epoch 33/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0715 - acc: 0.9844\n","Epoch 33: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 178ms/step - loss: 0.0715 - acc: 0.9844 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 3.2000e-07\n","Epoch 34/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0746 - acc: 0.9807\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n","\n","Epoch 34: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 168ms/step - loss: 0.0746 - acc: 0.9807 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 3.2000e-07\n","Epoch 35/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0730 - acc: 0.9818\n","Epoch 35: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 180ms/step - loss: 0.0730 - acc: 0.9818 - val_loss: 0.1541 - val_acc: 0.9479 - lr: 6.4000e-08\n","Epoch 36/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0724 - acc: 0.9839\n","Epoch 36: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n","\n","Epoch 36: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0724 - acc: 0.9839 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 6.4000e-08\n","Epoch 37/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0732 - acc: 0.9812\n","Epoch 37: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0732 - acc: 0.9812 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 1.2800e-08\n","Epoch 38/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0721 - acc: 0.9818\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n","\n","Epoch 38: val_acc did not improve from 0.95208\n","60/60 [==============================] - 11s 177ms/step - loss: 0.0721 - acc: 0.9818 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 1.2800e-08\n","Epoch 39/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.9807\n","Epoch 39: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0712 - acc: 0.9807 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 2.5600e-09\n","Epoch 40/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0695 - acc: 0.9859\n","Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-09.\n","\n","Epoch 40: val_acc did not improve from 0.95208\n","60/60 [==============================] - 10s 167ms/step - loss: 0.0695 - acc: 0.9859 - val_loss: 0.1542 - val_acc: 0.9479 - lr: 2.5600e-09\n","Batch size: 64\n","\n","Epoch 1/40\n","30/30 [==============================] - ETA: 0s - loss: 1.0567 - acc: 0.5594\n","Epoch 1: val_acc did not improve from 0.95208\n","30/30 [==============================] - 15s 352ms/step - loss: 1.0567 - acc: 0.5594 - val_loss: 0.6658 - val_acc: 0.5562 - lr: 0.0010\n","Epoch 2/40\n","30/30 [==============================] - ETA: 0s - loss: 0.4949 - acc: 0.7583\n","Epoch 2: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 335ms/step - loss: 0.4949 - acc: 0.7583 - val_loss: 0.4520 - val_acc: 0.7833 - lr: 0.0010\n","Epoch 3/40\n","30/30 [==============================] - ETA: 0s - loss: 0.3925 - acc: 0.8349\n","Epoch 3: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 339ms/step - loss: 0.3925 - acc: 0.8349 - val_loss: 0.3688 - val_acc: 0.8479 - lr: 0.0010\n","Epoch 4/40\n","30/30 [==============================] - ETA: 0s - loss: 0.3094 - acc: 0.8839\n","Epoch 4: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 334ms/step - loss: 0.3094 - acc: 0.8839 - val_loss: 0.3596 - val_acc: 0.8313 - lr: 0.0010\n","Epoch 5/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2873 - acc: 0.8958\n","Epoch 5: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.2873 - acc: 0.8958 - val_loss: 0.2682 - val_acc: 0.9083 - lr: 0.0010\n","Epoch 6/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2330 - acc: 0.9240\n","Epoch 6: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.2330 - acc: 0.9240 - val_loss: 0.2564 - val_acc: 0.9021 - lr: 0.0010\n","Epoch 7/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2143 - acc: 0.9240\n","Epoch 7: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 330ms/step - loss: 0.2143 - acc: 0.9240 - val_loss: 0.2400 - val_acc: 0.9250 - lr: 0.0010\n","Epoch 8/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2014 - acc: 0.9328\n","Epoch 8: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.2014 - acc: 0.9328 - val_loss: 0.2169 - val_acc: 0.9083 - lr: 0.0010\n","Epoch 9/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9516\n","Epoch 9: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 331ms/step - loss: 0.1617 - acc: 0.9516 - val_loss: 0.2099 - val_acc: 0.9333 - lr: 0.0010\n","Epoch 10/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1615 - acc: 0.9422\n","Epoch 10: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.1615 - acc: 0.9422 - val_loss: 0.2262 - val_acc: 0.9104 - lr: 0.0010\n","Epoch 11/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1695 - acc: 0.9391\n","Epoch 11: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.1695 - acc: 0.9391 - val_loss: 0.1858 - val_acc: 0.9396 - lr: 0.0010\n","Epoch 12/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1331 - acc: 0.9578\n","Epoch 12: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.1331 - acc: 0.9578 - val_loss: 0.3148 - val_acc: 0.8438 - lr: 0.0010\n","Epoch 13/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1375 - acc: 0.9563\n","Epoch 13: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.1375 - acc: 0.9563 - val_loss: 0.1655 - val_acc: 0.9396 - lr: 0.0010\n","Epoch 14/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1035 - acc: 0.9703\n","Epoch 14: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.1035 - acc: 0.9703 - val_loss: 0.1837 - val_acc: 0.9271 - lr: 0.0010\n","Epoch 15/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1079 - acc: 0.9641\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 15: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.1079 - acc: 0.9641 - val_loss: 0.1812 - val_acc: 0.9438 - lr: 0.0010\n","Epoch 16/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0883 - acc: 0.9734\n","Epoch 16: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 334ms/step - loss: 0.0883 - acc: 0.9734 - val_loss: 0.1552 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 17/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0867 - acc: 0.9771\n","Epoch 17: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0867 - acc: 0.9771 - val_loss: 0.1549 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 18/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9797\n","Epoch 18: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0837 - acc: 0.9797 - val_loss: 0.1620 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 19/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0784 - acc: 0.9792\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 19: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0784 - acc: 0.9792 - val_loss: 0.1594 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 20/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0778 - acc: 0.9818\n","Epoch 20: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0778 - acc: 0.9818 - val_loss: 0.1604 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 21/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0746 - acc: 0.9844\n","Epoch 21: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0746 - acc: 0.9844 - val_loss: 0.1546 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 22/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9828\n","Epoch 22: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 331ms/step - loss: 0.0772 - acc: 0.9828 - val_loss: 0.1556 - val_acc: 0.9479 - lr: 4.0000e-05\n","Epoch 23/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0829 - acc: 0.9797\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 23: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0829 - acc: 0.9797 - val_loss: 0.1545 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 24/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0754 - acc: 0.9823\n","Epoch 24: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.0754 - acc: 0.9823 - val_loss: 0.1547 - val_acc: 0.9458 - lr: 8.0000e-06\n","Epoch 25/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0771 - acc: 0.9802\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 25: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.0771 - acc: 0.9802 - val_loss: 0.1555 - val_acc: 0.9500 - lr: 8.0000e-06\n","Epoch 26/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0777 - acc: 0.9812\n","Epoch 26: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0777 - acc: 0.9812 - val_loss: 0.1556 - val_acc: 0.9500 - lr: 1.6000e-06\n","Epoch 27/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0776 - acc: 0.9818\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 27: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0776 - acc: 0.9818 - val_loss: 0.1551 - val_acc: 0.9479 - lr: 1.6000e-06\n","Epoch 28/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0759 - acc: 0.9844\n","Epoch 28: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0759 - acc: 0.9844 - val_loss: 0.1551 - val_acc: 0.9479 - lr: 3.2000e-07\n","Epoch 29/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9812\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n","\n","Epoch 29: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 333ms/step - loss: 0.0772 - acc: 0.9812 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 3.2000e-07\n","Epoch 30/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0766 - acc: 0.9823\n","Epoch 30: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0766 - acc: 0.9823 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 6.4000e-08\n","Epoch 31/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.9818\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n","\n","Epoch 31: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0758 - acc: 0.9818 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 6.4000e-08\n","Epoch 32/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0796 - acc: 0.9802\n","Epoch 32: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 334ms/step - loss: 0.0796 - acc: 0.9802 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.2800e-08\n","Epoch 33/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0787 - acc: 0.9797\n","Epoch 33: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n","\n","Epoch 33: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 335ms/step - loss: 0.0787 - acc: 0.9797 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.2800e-08\n","Epoch 34/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9823\n","Epoch 34: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0751 - acc: 0.9823 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 2.5600e-09\n","Epoch 35/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0811 - acc: 0.9802\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-09.\n","\n","Epoch 35: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0811 - acc: 0.9802 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 2.5600e-09\n","Epoch 36/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0742 - acc: 0.9833\n","Epoch 36: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0742 - acc: 0.9833 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.0000e-09\n","Epoch 37/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0798 - acc: 0.9755\n","Epoch 37: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0798 - acc: 0.9755 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.0000e-09\n","Epoch 38/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0721 - acc: 0.9828\n","Epoch 38: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0721 - acc: 0.9828 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.0000e-09\n","Epoch 39/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0774 - acc: 0.9807\n","Epoch 39: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 332ms/step - loss: 0.0774 - acc: 0.9807 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.0000e-09\n","Epoch 40/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0750 - acc: 0.9833\n","Epoch 40: val_acc did not improve from 0.95208\n","30/30 [==============================] - 10s 335ms/step - loss: 0.0750 - acc: 0.9833 - val_loss: 0.1550 - val_acc: 0.9479 - lr: 1.0000e-09\n"]}]},{"cell_type":"code","source":["# predikcije\n","loaded_model = tf.keras.models.load_model('/content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model - histogram equal')"],"metadata":{"id":"SZeoyue0zX97","executionInfo":{"status":"ok","timestamp":1672340167064,"user_tz":-60,"elapsed":1227,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["score = loaded_model.evaluate(test_x, y_test, verbose=1)"],"metadata":{"id":"eXkgJUNWz2vy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672340171523,"user_tz":-60,"elapsed":3433,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"d0cb9a0e-a0c7-4792-bf18-3171138b1228"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 3s 133ms/step - loss: 0.1463 - acc: 0.9417\n"]}]},{"cell_type":"code","source":["output = loaded_model.predict(test_x, verbose=True)\n","y_predicted = np.where(output > .5, 1, 0)\n","\n","accuracy = metrics.accuracy_score(y_test, y_predicted)\n","recall = metrics.recall_score(y_test, y_predicted)\n","f1 = metrics.f1_score(y_test, y_predicted)\n","\n","print(f'Accuracy: {accuracy}; Recall: {recall}; F1: {f1}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHoTs6OC94-L","executionInfo":{"status":"ok","timestamp":1672338860327,"user_tz":-60,"elapsed":2983,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"e4de12e9-8993-456e-a144-aebb8955ece1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 3s 134ms/step\n","Accuracy: 0.9416666666666667; Recall: 0.9303135888501742; F1: 0.9384885764499121\n"]}]},{"cell_type":"code","source":["cm = metrics.ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_predicted, colorbar=False, display_labels=['No Tumor', 'Tumor'])\n","cm.ax_.set(xlabel='Predicted', ylabel='True')\n","cm.figure_.set_size_inches(5, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"KHWChyCe-Cau","executionInfo":{"status":"ok","timestamp":1672338864244,"user_tz":-60,"elapsed":390,"user":{"displayName":"Tihomir Pavić","userId":"18415611717136323973"}},"outputId":"8a06b028-3d16-4999-82ab-d6c794a7410f"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 360x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}